{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdpbiiitd/CSE508_Winter2023_A2_39./blob/main/IR_A2_Improvements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwb1wKUCDXmW",
        "outputId": "bdc9dfc6-824a-48be-8433-1f8a2d36fe65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "import math\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6hdg3htdBrn",
        "outputId": "a3022eba-8f76-4312-ea07-2ce715b74676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ArticleId                                               Text  Category\n",
            "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
            "1        154  german business confidence slides german busin...  business\n",
            "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
            "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
            "4        917  enron bosses in $168m payout eighteen former e...  business\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('dataset.csv')\n",
        "#df = df.drop('ArticleId', axis=1)\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wlKYrcTshwOZ"
      },
      "outputs": [],
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = \" \".join([word.lower() for word in text.split() if word.lower() not in stopwords])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nELC8mSoh4Pu"
      },
      "outputs": [],
      "source": [
        "df['Text'] = df['Text'].apply(clean_text)\n",
        "df['Text'] = df['Text'].apply(word_tokenize)\n",
        "df['Text'] = df['Text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
        "df['Text'] = df['Text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TF\n",
        "tf = defaultdict(Counter)\n",
        "for i, row in df.iterrows():\n",
        "    for word in row['Text']:\n",
        "        tf[row['Category']][word] += 1\n",
        "\n",
        "# Calculate ICF\n",
        "N = len(df)\n",
        "icf = {}\n",
        "for word in set(df['Text'].sum()):\n",
        "    n_t = sum([1 for i, row in df.iterrows() if word in row['Text']])\n",
        "    icf[word] = math.log(N / n_t)\n",
        "\n",
        "# Calculate TF-ICF\n",
        "tf_icf = defaultdict(dict)\n",
        "for label, counter in tf.items():\n",
        "    for word, count in counter.items():\n",
        "        tf_icf[label][word] = count * icf[word]"
      ],
      "metadata": {
        "id": "dBHxobrEn2If"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of dictionaries\n",
        "X = df['Text'].apply(lambda x: dict(Counter(x))).tolist()"
      ],
      "metadata": {
        "id": "2TYVBXjQwpaT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1_h48nb6BX2",
        "outputId": "b495998f-a2cb-405a-ea98-fa5ffdd51d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['business' 'tech' 'politics' 'sport' 'entertainment']\n"
          ]
        }
      ],
      "source": [
        "print(df['Category'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets using a 70:30 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df['Category'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a MultinomialNB classifier\n",
        "clf = MultinomialNB()\n",
        "\n",
        "# Create a DictVectorizer object\n",
        "vec = DictVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training set\n",
        "vec.fit(X_train)\n",
        "\n",
        "# Transform the training set\n",
        "X_train = vec.transform(X_train)\n",
        "\n",
        "# Transform the testing set\n",
        "X_test = vec.transform(X_test)\n",
        "\n",
        "# Fit the classifier on the training set\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "0hqeooYFG-GY",
        "outputId": "bdf66437-8244-4aa7-f5a3-c024e0c7d7eb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print results\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'Precision: {precision:.2f}')\n",
        "print(f'Recall: {recall:.2f}')\n",
        "print(f'F1 score: {f1:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsOUqoHnK0Zo",
        "outputId": "42be229a-7356-4c72-d43d-388e78242458"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n",
            "Precision: 0.98\n",
            "Recall: 0.98\n",
            "F1 score: 0.98\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhEo6IrxvC9tzhL5l+MrkR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}